version: 2
jobs: # a collection of steps
  build: # runs not using Workflows must have a `build` job as entry point
    working_directory: ~/first_repository # directory where steps will run
    docker: # run the steps with Docker
      - image: circleci/python:3.7.0 # ...with this image as the primary container; this is where all `steps` will run
    steps:
      # a collection of executable commands
      - checkout # special step to check out source code to the working directory
      - run: # install and activate virtual environment with pip
          name: install dependencies
          command: |
            python3 -m venv venv
            . venv/bin/activate
            pip install -r requirements.txt
       
      - run:
          name: kaggle
          command: |
            . venv/bin/activate
            export KAGGLE_USERNAME=datadinosaur
            export KAGGLE_KEY=c0a1546c96be24654a0ea24f6a3e4613
            mkdir .kaggle
            mv kaggle.json .kaggle
            kaggle competitions download titanic
            jupyter-nbconvert â€”execute titanic-mirosh.ipynb
            kaggle competitions submit titanic -f titanic.csv -m "My submission messsage"
          paths:
            - "venv"
      - run: # run tests
          name: run tests
          command: |
            . venv/bin/activate
            jupyter-nbconvert --execute plot_iris_dataset.ipynb
            mkdir -p task_2
            mv plot_iris_dataset.html task_2
      - store_artifacts: # special step to store test reports as artifacts
          path: task_2
          destination: task_2
      # See https://circleci.com/docs/2.0/deployment-integrations/ for deploy examples    
     
