{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "_uuid": "119f40cf598d5887871b6da88bb1a0030149a640"
   },
   "outputs": [],
   "source": [
    "#import all needed packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv as csv\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "addpoly = True\n",
    "plot_lc = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a97a4e8d98f6e98d3027301810c6fce064fc9b5e"
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fe5da40f372f6c78cbd755977d9e7c5d65301258"
   },
   "source": [
    "Анализируем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d4026e422ca9338ad38e42b1f8433656ecb5a4b7"
   },
   "outputs": [],
   "source": [
    "# Смотрим как пол влияет на шанс спастись\n",
    "print(df_train[['Sex', 'Survived']].groupby(['Sex']).mean())\n",
    "sns.catplot(x='Sex', y='Survived',  kind='bar', data=df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b7fae1198f989495cad86ceeeb6061597c99e2c5"
   },
   "source": [
    "Женщин спаслось намного больше"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c8912ad0a458fbef6152b95ff020724fb9db1652"
   },
   "outputs": [],
   "source": [
    "# Смотрим, как класс влияет на шанс спастись\n",
    "print(df_train[['Pclass', 'Survived']].groupby(['Pclass'], \n",
    "                                                    as_index=False).mean().sort_values(by='Survived', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0cbb5f5cc75b6547ffacfe2fd9f95ab2ff21f661"
   },
   "source": [
    "Выживших пассажиров 1 класса больше всего"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b9bceccd870b31f52a12fc935ac7afc9d7528142"
   },
   "outputs": [],
   "source": [
    "# Смотрим, как количесво родственников влияет на шанс спастись\n",
    "sns.catplot(x='SibSp', y='Survived', data=df_train, kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3b971fc67e8ab1fbac54446be4bb0695ec3edd2d"
   },
   "source": [
    "Чем меньше родственников, тем больше выживаемость"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "aca8027b184df9c16a52aadfd59c1f2973c383ca"
   },
   "outputs": [],
   "source": [
    "# Смотрим, как Parch влияет на шанс спастись \n",
    "print(df_train[[\"Parch\", \"Survived\"]].groupby(['Parch'], \n",
    "                                                   as_index=False).mean().sort_values(by='Survived', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2707869190bd1646cf38a83644229d3ba4e40224"
   },
   "source": [
    "Заполним пропуски в данных и делаем новые признаки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ad921018d486cebee3b4deb6fa21480c946afe46"
   },
   "outputs": [],
   "source": [
    "#Age\n",
    "train_random_ages = np.random.randint(df_train[\"Age\"].mean() - df_train[\"Age\"].std(),\n",
    "                                          df_train[\"Age\"].mean() + df_train[\"Age\"].std(),\n",
    "                                          size = df_train[\"Age\"].isnull().sum())\n",
    "\n",
    "test_random_ages = np.random.randint(df_test[\"Age\"].mean() - df_test[\"Age\"].std(),\n",
    "                                          df_test[\"Age\"].mean() + df_test[\"Age\"].std(),\n",
    "                                          size = df_test[\"Age\"].isnull().sum())\n",
    "\n",
    "df_train[\"Age\"][np.isnan(df_train[\"Age\"])] = train_random_ages\n",
    "df_test[\"Age\"][np.isnan(df_test[\"Age\"])] = test_random_ages\n",
    "df_train['Age'] = df_train['Age'].astype(int)\n",
    "df_test['Age']    = df_test['Age'].astype(int)\n",
    "\n",
    "# Embarked \n",
    "df_train[\"Embarked\"].fillna('S', inplace=True)\n",
    "df_test[\"Embarked\"].fillna('S', inplace=True)\n",
    "df_train['Port'] = df_train['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n",
    "df_test['Port'] = df_test['Embarked'].map({'S': 0, 'C': 1, 'Q': 2}).astype(int)\n",
    "del df_train['Embarked']\n",
    "del df_test['Embarked']\n",
    "\n",
    "# Fare\n",
    "df_test[\"Fare\"].fillna(df_test[\"Fare\"].median(), inplace=True)\n",
    "\n",
    "# Cabin меняем на Has_Cabin\n",
    "df_train['Has_Cabin'] = df_train[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\n",
    "df_test['Has_Cabin'] = df_test[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\n",
    "\n",
    "all_data = [df_train,df_test]\n",
    "\n",
    "# Так как выживаемость в одиночку выше, сделаем специальный признак IsAlone\n",
    "for dataset in all_data:\n",
    "    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n",
    "\n",
    "for dataset in all_data:\n",
    "    dataset['IsAlone'] = 0\n",
    "    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1\n",
    "\n",
    "for dataset in all_data:\n",
    "    dataset['FamilySizeGroup'] = 'Small'\n",
    "    dataset.loc[dataset['FamilySize'] == 1, 'FamilySizeGroup'] = 'Alone'\n",
    "    dataset.loc[dataset['FamilySize'] >= 5, 'FamilySizeGroup'] = 'Big'\n",
    "    \n",
    "family_mapping = {\"Small\": 0, \"Alone\": 1, \"Big\": 2}\n",
    "\n",
    "for dataset in all_data:\n",
    "    dataset['FamilySizeGroup'] = dataset['FamilySizeGroup'].map(family_mapping)\n",
    "\n",
    "    \n",
    "# Меняем Age, Sex и Fare    \n",
    "for dataset in all_data:\n",
    "    dataset['Sex'] = dataset['Sex'].map( {'female': 1, 'male': 0} ).astype(int)\n",
    "        \n",
    "for dataset in all_data:    \n",
    "    dataset.loc[ dataset['Age'] <= 14, 'Age'] = 0\n",
    "    dataset.loc[(dataset['Age'] > 14) & (dataset['Age'] <= 32), 'Age'] = 1\n",
    "    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n",
    "    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n",
    "    dataset.loc[ dataset['Age'] > 64, 'Age'] = 4\n",
    "\n",
    "for dataset in all_data:\n",
    "    dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] = 0\n",
    "    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n",
    "    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\n",
    "    dataset.loc[ dataset['Fare'] > 31, 'Fare'] = 3\n",
    "    dataset['Fare'] = dataset['Fare'].astype(int)\n",
    "\n",
    "# Делаем еще один признак    \n",
    "for dataset in all_data:\n",
    "    dataset['IsChildandRich'] = 0\n",
    "    dataset.loc[(dataset['Age'] <= 0) & (dataset['Pclass'] == 1 ),'IsChildandRich'] = 1  \n",
    "    dataset.loc[(dataset['Age'] <= 0) & (dataset['Pclass'] == 2 ),'IsChildandRich'] = 1  \n",
    "\n",
    "# Удаляем ненужные признаки\n",
    "\n",
    "del df_train['Name']\n",
    "del df_test['Name']\n",
    "\n",
    "del df_train['SibSp']\n",
    "del df_test['SibSp']\n",
    "\n",
    "del df_train['Parch']\n",
    "del df_test['Parch']\n",
    "\n",
    "del df_train['FamilySize']\n",
    "del df_test['FamilySize']\n",
    "\n",
    "del df_train['Cabin']\n",
    "del df_test['Cabin']\n",
    "\n",
    "del df_train['Ticket']\n",
    "del df_test['Ticket']\n",
    "\n",
    "del df_train['Port']\n",
    "del df_test['Port']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "06a73d6bf8fa62116255ad1a405e60cdf3e9ce24"
   },
   "outputs": [],
   "source": [
    "print('train dataset: %s, test dataset %s' %(str(df_train.shape), str(df_test.shape)) )\n",
    "df_train.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "132a0aa329608f5e5bca7614925472a72526910f"
   },
   "outputs": [],
   "source": [
    "del df_train['PassengerId']\n",
    "\n",
    "X_train = df_train.drop(\"Survived\",axis=1)\n",
    "Y_train = df_train[\"Survived\"]\n",
    "X_test  = df_test.drop(\"PassengerId\",axis=1).copy()\n",
    "\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "601f202a61eb4c03de03212877997a85a0a48ed2"
   },
   "outputs": [],
   "source": [
    "# KNN\n",
    "alg_KNN = KNeighborsClassifier(n_neighbors=3)\n",
    "alg_KNN.fit(X_train,Y_train)\n",
    "\n",
    "result_train = alg_KNN.score(X_train,Y_train)\n",
    "result_val = cross_val_score(alg_KNN, X_train, Y_train, cv=5).mean()\n",
    "print(result_train,result_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4cd6b7c1860c74aac34ffd7128de82299d5b0fb0"
   },
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "logreg = LogisticRegression() \n",
    "logreg.fit(X_train, Y_train)\n",
    "Y_pred = logreg.predict(X_test)\n",
    "\n",
    "result_train = logreg.score(X_train, Y_train)\n",
    "result_val = cross_val_score(logreg,X_train, Y_train, cv=5).mean()\n",
    "print(result_train , result_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8d8c849b0319d8493d4d43350f1767d9071d9429"
   },
   "outputs": [],
   "source": [
    "# RandomForest\n",
    "random_forest = RandomForestClassifier(criterion='gini', \n",
    "                             n_estimators=1000,\n",
    "                             min_samples_split=10,\n",
    "                             min_samples_leaf=1,\n",
    "                             max_features='auto',\n",
    "                             oob_score=True,\n",
    "                             random_state=1,\n",
    "                             n_jobs=-1)\n",
    "\n",
    "seed= 42\n",
    "random_forest =RandomForestClassifier(n_estimators=1000, criterion='entropy', max_depth=5, min_samples_split=2,\n",
    "                           min_samples_leaf=1, max_features='auto',    bootstrap=False, oob_score=False, \n",
    "                           n_jobs=1, random_state=seed,verbose=0)\n",
    "\n",
    "random_forest.fit(X_train, Y_train)\n",
    "Y_pred = random_forest.predict(X_test)\n",
    "\n",
    "result_train = random_forest.score(X_train, Y_train)\n",
    "result_val = cross_val_score(random_forest,X_train, Y_train, cv=5).mean()\n",
    "\n",
    "print(result_train , result_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e8bb96a1f8dda48f211a43d3bce9d6a4304fe71f"
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "        \"PassengerId\": df_test[\"PassengerId\"],\n",
    "        \"Survived\": Y_pred\n",
    "    })\n",
    "submission.to_csv('titanic.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
